{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama, HuggingFaceHub, HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# print(GPUtil.showUtilization())\n",
    "# OPENAI_API_KEY = getpass()\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-proj-Y2nqeGoOCxTZnITAzuFdT3BlbkFJf6Rm2tmkcssXIov3PMFQ'\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = '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'\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\"\n",
    "os.environ['LANGCHAIN_ENDPOINT']=\"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_API_KEY']=\"ls__93636df794f14ccba7162354d46779d8\"\n",
    "os.environ['LANGCHAIN_PROJECT']=\"LLM_Context_Effects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf_repo_id_mapping = {\n",
    "    'mistral_7B': \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    'llama2_7B':'meta-llama/Llama-2-7b-chat-hf',\n",
    "    'llama2_13B': 'meta-llama/Llama-2-13b-chat-hf',\n",
    "    'llama2_70B': 'meta-llama/Llama-2-70b-chat-hf',\n",
    "    'llama3_8B':'meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "    'llama3_70B': 'meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "}\n",
    "\n",
    "model_ollama_id_mapping = {\n",
    "    'mistral_7B': \"mistral:7b-instruct-fp16\",\n",
    "    'llama2_7B': 'llama2:7b-chat-fp16',\n",
    "    'llama2_13B': 'llama2:13b-chat-fp16',\n",
    "    'llama2_70B': 'llama2:70b-chat-fp16',\n",
    "    'llama3_8B':'llama3:8b-instruct-fp16',\n",
    "    'llama3_70B': 'llama3:70b-instruct-fp16'\n",
    "}\n",
    "\n",
    "model_name_type_mapping={\n",
    "    'gpt-3.5-turbo': 'openai',\n",
    "    'gpt-4': 'openai',\n",
    "    'mistral_7B': 'open-source',\n",
    "    'llama2_7B': 'open-source',\n",
    "    'llama2_13B': 'open-source',\n",
    "    'llama2_70B': 'open-source',\n",
    "    'llama3_8B': 'open-source',\n",
    "    'llama3_70B': 'open-source',\n",
    "}\n",
    "\n",
    "def initialise_openai_models(model_name, temperature):\n",
    "    model = ChatOpenAI(model=model_name, api_key=os.environ[\"OPENAI_API_KEY\"], temperature=temperature, max_tokens=200)\n",
    "    return model\n",
    "\n",
    "def initialise_open_source_models_transformers(model_name, temperature):\n",
    "    # Use a pipeline as a high-level helper\n",
    "    repo_id = model_hf_repo_id_mapping[model_name]\n",
    "    pipe = pipeline(\"text-generation\",\n",
    "                    model=repo_id,\n",
    "                    token=os.environ['HUGGINGFACEHUB_API_TOKEN'],\n",
    "                    device_map = \"sequential\", max_new_tokens = 10,\n",
    "                    do_sample = True,\n",
    "                    return_full_text = False,\n",
    "                    temperature = temperature,\n",
    "                    top_k = 50,\n",
    "                    top_p = 0.9)\n",
    "    return  HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "def initialise_open_source_models_ollama(model_name, temperature):\n",
    "    ollama_id = model_ollama_id_mapping[model_name]\n",
    "    model = Ollama(base_url='http://localhost:11434',\n",
    "    model=ollama_id, temperature = temperature, num_predict = 10, format = 'json', num_gpu=-1)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def initialise_models(model_name = 'mistral_7B', model_type = 'openai', temperature= 0.0):\n",
    "    if model_type == 'openai':\n",
    "        return initialise_openai_models(model_name, temperature)\n",
    "    else:\n",
    "        return initialise_open_source_models_ollama(model_name, temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the following question to the best of your knowledge. Your answer should be a json of shape provided.\n",
    "Text: {text}\n",
    "\"\"\"\n",
    "modified_template = \"\"\"Answer the following question to the best of your knowledge.  Your answer should be a json of shape provided.\n",
    "                                Text: {text}\n",
    "                                Please provide an integer score.\n",
    "                     \"\"\"\n",
    "template_cot = \"\"\"Answer the following question to the best of your knowledge. Your answer should be a json of shape provided. Also, mention how you arrived at the score.\n",
    "Text: {text}\n",
    "Lets think step by step.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "modified_prompt = ChatPromptTemplate.from_template(modified_template)\n",
    "prompt_cot = ChatPromptTemplate.from_template(template_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [0.001, 0.5, 1.0, 1.5]\n",
    "similarity_effect_country_pairs = [\n",
    "('U.S.A.', 'Mexico'),\n",
    "('U.S.S.R.', 'Poland'),\n",
    "('China', 'Albania'),\n",
    "('U.S.A.', 'Israel'),\n",
    "('Japan', 'Philippines'),\n",
    "('U.S.A.', 'Canada'),\n",
    "('U.S.S.R.', 'Israel'),\n",
    "('England', 'Ireland'),\n",
    "('Germany', 'Austria'),\n",
    "('U.S.S.R.', 'France'),\n",
    "('Belgium', 'Luxembourg'),\n",
    "('U.S.A.', 'U.S.S.R.'),\n",
    "('China', 'North Korea'),\n",
    "('India', 'Sri Lanka'),\n",
    "('U.S.A.', 'France'),\n",
    "('U.S.S.R.', 'Cuba'),\n",
    "('England', 'Jordan'),\n",
    "('France', 'Israel'),\n",
    "('U.S.A.', 'Germany'),\n",
    "('U.S.S.R.', 'Syria'),\n",
    "('France', 'Algeria')]\n",
    "\n",
    "SSA_order_1 = {}\n",
    "SSA_order_2 = {}\n",
    "\n",
    "SST_order_1 = {}\n",
    "SST_order_2 = {}\n",
    "\n",
    "SSD_order_1 = {}\n",
    "SSD_order_2 = {}\n",
    "\n",
    "\n",
    "for country1, country2 in similarity_effect_country_pairs:\n",
    "    order_1 = f'{country1}-{country2}'\n",
    "    order_2 = f'{country2}-{country1}'\n",
    "    SSA_order_1[order_1] = f\"\"\"\n",
    "    On a scale of 0 to 20, where 0 means no similarity and 20 means complete similarity, how similar are {country1} and {country2}?\n",
    "    Please rate overall similarity and base your judgement on the following factors:\n",
    "    1. Economy\n",
    "    2. Politics and Governance\n",
    "    3. Culture, Religion and Ethnicity\n",
    "    4. History\n",
    "    5. Geography and Borders\n",
    "    6. International Relations and Influence\n",
    "    7. Defense and Military Conflict\n",
    "\n",
    "    Structure your response in the following json format:\n",
    "    score: int\"\"\"\n",
    "\n",
    "\n",
    "    SSA_order_2[order_2] = f\"\"\"\n",
    "    On a scale of 0 to 20, where 0 means no similarity and 20 means complete similarity, how similar are {country2} and {country1}?\n",
    "    Please rate overall similarity and base your judgement on the following factors:\n",
    "    1. Economy\n",
    "    2. Politics and Governance\n",
    "    3. Culture, Religion and Ethnicity\n",
    "    4. History\n",
    "    5. Geography and Borders\n",
    "    6. International Relations and Influence\n",
    "    7. Defense and Military Conflict\n",
    "\n",
    "    Structure your response in the following json format:\n",
    "    score: int\"\"\"\n",
    "\n",
    "    SST_order_1[order_1] = f\"\"\"\n",
    "    On a scale of 0 to 20, where 0 means no similarity and 20 means complete similarity, is {country1} similar to {country2}?\n",
    "    Please rate overall similarity and base your judgement on the following factors:\n",
    "    1. Economy\n",
    "    2. Politics and Governance\n",
    "    3. Culture, Religion and Ethnicity\n",
    "    4. History\n",
    "    5. Geography and Borders\n",
    "    6. International Relations and Influence\n",
    "    7. Defense and Military Conflict\n",
    "\n",
    "    Structure your response in the following json format:\n",
    "    score: int\"\"\"\n",
    "\n",
    "\n",
    "    SST_order_2[order_2] = f\"\"\"\n",
    "    On a scale of 0 to 20, where 0 means no similarity and 20 means complete similarity, is {country2} similar to {country1}?\n",
    "    Please rate overall similarity and base your judgement on the following factors:\n",
    "    1. Economy\n",
    "    2. Politics and Governance\n",
    "    3. Culture, Religion and Ethnicity\n",
    "    4. History\n",
    "    5. Geography and Borders\n",
    "    6. International Relations and Influence\n",
    "    7. Defense and Military Conflict\n",
    "\n",
    "    Structure your response in the following json format:\n",
    "    score: int\"\"\"\n",
    "\n",
    "    SSD_order_1[order_1] = f\"\"\"On a scale of 0 to 20, where 0 means no similarity and 20 means complete similarity, assess the degree to which {country1} is similar to {country2}?\n",
    "    Please rate overall similarity and base your judgement on the following factors:\n",
    "    1. Economy\n",
    "    2. Politics and Governance\n",
    "    3. Culture, Religion and Ethnicity\n",
    "    4. History\n",
    "    5. Geography and Borders\n",
    "    6. International Relations and Influence\n",
    "    7. Defense and Military Conflict\n",
    "\n",
    "    Structure your response in the following json format:\n",
    "    score: int\"\"\"\n",
    "    SSD_order_2[order_2] = f\"\"\"On a scale of 0 to 20, where 0 means no similarity and 20 means complete similarity, assess the degree to which {country2} is similar to {country1}? \n",
    "    Please rate overall similarity and base your judgement on the following factors:\n",
    "    1. Economy\n",
    "    2. Politics and Governance\n",
    "    3. Culture, Religion and Ethnicity\n",
    "    4. History\n",
    "    5. Geography and Borders\n",
    "    6. International Relations and Influence\n",
    "    7. Defense and Military Conflict\n",
    "\n",
    "    Structure your response in the following json format:\n",
    "    score: int\"\"\"\n",
    "\n",
    "# print(questions_order_similar_degree_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style_template_mapping = {\n",
    "    'SD': {'order_1': SSD_order_1, 'order_2': SSD_order_2},\n",
    "    'ST':{'order_1': SST_order_1, 'order_2': SST_order_2},\n",
    "    'SA':{'order_1': SSA_order_1, 'order_2': SSA_order_2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [country_pair, prompt_style, model_name, temperature, sim_score_1, sim_score_2, sim_diff]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "results_dict_columns = {\n",
    "    'country_pair': '',\n",
    "    'prompt_style': '',\n",
    "    'model_name': '',\n",
    "    'temperature': '',\n",
    "    'sim_score_1': [],\n",
    "    'sim_score_2': [],\n",
    "    'sim_diff': [],\n",
    "}\n",
    "# Define the file path\n",
    "file_path = './results/results_single_factor_based.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(file_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "else:\n",
    "    # Create an empty DataFrame from the dictionary\n",
    "    df = pd.DataFrame(columns=results_dict_columns)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(prompt, model, order, model_name, temperature):\n",
    "    return (prompt | model | StrOutputParser()).with_config({\n",
    "\"metadata\": {\n",
    "    'country-pair-order': order,\n",
    "    'model_name':model_name,\n",
    "    'temperature': temperature,\n",
    "}}\n",
    ")\n",
    "\n",
    "def get_output(prompt, model, order, model_name, temperature, ques):\n",
    "    chain = create_chain(prompt, model, order, model_name, temperature)\n",
    "    return chain.invoke({\"text\": ques})\n",
    "\n",
    "def parse_numeric_output(raw_output):\n",
    "    match = re.search(r'\\d+', raw_output)\n",
    "    # print(match, match.group())\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return None\n",
    "\n",
    "def parse_cot_json_output(raw_output):\n",
    "    raw_output = raw_output.replace(\"\\n\", \" \")\n",
    "    # json_dict = json.loads(raw_output)\n",
    "    score = reasoning = None\n",
    "    try:\n",
    "        json_dict = json.loads(raw_output)\n",
    "    except:\n",
    "        print(f'error in parsing raw output to json. output is {raw_output}')\n",
    "        return reasoning, score, True\n",
    "\n",
    "    if 'score' in json_dict.keys():\n",
    "        score = json_dict['score']\n",
    "\n",
    "    if 'Reasoning' in json_dict.keys():\n",
    "        reasoning = json_dict['Reasoning']\n",
    "\n",
    "    return reasoning, score, False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOllama\u001b[0m\n",
      "Params: {'model': 'llama3:8b-instruct-fp16', 'format': 'json', 'options': {'mirostat': None, 'mirostat_eta': None, 'mirostat_tau': None, 'num_ctx': None, 'num_gpu': -1, 'num_thread': None, 'num_predict': 10, 'repeat_last_n': None, 'repeat_penalty': None, 'temperature': 0.001, 'stop': None, 'tfs_z': None, 'top_k': None, 'top_p': None}, 'system': None, 'template': None, 'keep_alive': None}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Mexico, Temperature: 0.001, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1714515/1765307831.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame.from_dict([results_dict_columns])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Poland, Temperature: 0.001, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: China-Albania, Temperature: 0.001, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Israel, Temperature: 0.001, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: Japan-Philippines, Temperature: 0.001, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Canada, Temperature: 0.001, output1: {\n",
      "\"score\": 14\n",
      "}, output2: {\n",
      "\"score\": 14\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Israel, Temperature: 0.001, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: England-Ireland, Temperature: 0.001, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: Germany-Austria, Temperature: 0.001, output1: {\n",
      "\"score\": 14\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-France, Temperature: 0.001, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: Belgium-Luxembourg, Temperature: 0.001, output1: {\n",
      "\"score\": 14\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-U.S.S.R., Temperature: 0.001, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: China-North Korea, Temperature: 0.001, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: India-Sri Lanka, Temperature: 0.001, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-France, Temperature: 0.001, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Cuba, Temperature: 0.001, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: England-Jordan, Temperature: 0.001, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: France-Israel, Temperature: 0.001, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Germany, Temperature: 0.001, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Syria, Temperature: 0.001, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: France-Algeria, Temperature: 0.001, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n",
      "\u001b[1mOllama\u001b[0m\n",
      "Params: {'model': 'llama3:8b-instruct-fp16', 'format': 'json', 'options': {'mirostat': None, 'mirostat_eta': None, 'mirostat_tau': None, 'num_ctx': None, 'num_gpu': -1, 'num_thread': None, 'num_predict': 10, 'repeat_last_n': None, 'repeat_penalty': None, 'temperature': 0.5, 'stop': None, 'tfs_z': None, 'top_k': None, 'top_p': None}, 'system': None, 'template': None, 'keep_alive': None}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Mexico, Temperature: 0.5, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 10\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Poland, Temperature: 0.5, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: China-Albania, Temperature: 0.5, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Israel, Temperature: 0.5, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: Japan-Philippines, Temperature: 0.5, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 4\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Canada, Temperature: 0.5, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 15\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Israel, Temperature: 0.5, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: England-Ireland, Temperature: 0.5, output1: {\n",
      "\"score\": 14\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: Germany-Austria, Temperature: 0.5, output1: {\n",
      "\"score\": 14\n",
      "}, output2: {\n",
      "\"score\": 12\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-France, Temperature: 0.5, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: Belgium-Luxembourg, Temperature: 0.5, output1: {\n",
      "\"score\": 15\n",
      "}, output2: {\n",
      "\"score\": 10\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-U.S.S.R., Temperature: 0.5, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: China-North Korea, Temperature: 0.5, output1: {\n",
      "\"score\": 10\n",
      "}, output2: {\n",
      "\"score\": 10\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: India-Sri Lanka, Temperature: 0.5, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 14\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-France, Temperature: 0.5, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Cuba, Temperature: 0.5, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: England-Jordan, Temperature: 0.5, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: France-Israel, Temperature: 0.5, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 4\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.A.-Germany, Temperature: 0.5, output1: {\n",
      "\"score\": 8\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: U.S.S.R.-Syria, Temperature: 0.5, output1: {\n",
      "\"score\": 2\n",
      "}, output2: {\n",
      "\"score\": 2\n",
      "}\n",
      "for Model_name: llama3_8B, Pair: France-Algeria, Temperature: 0.5, output1: {\n",
      "\"score\": 12\n",
      "}, output2: {\n",
      "\"score\": 8\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccaesup/miniconda3/envs/LLM_Context_Effects/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Model_name: gpt-4, Pair: U.S.A.-Mexico, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "\"Economy\": 8,\n",
      "\"Politics and Governance\": 7,\n",
      "\"Culture, Religion and Ethnicity\": 10,\n",
      "\"History\": 12,\n",
      "\"Geography and Borders\": 15,\n",
      "\"International Relations and Influence\": 10,\n",
      "\"Defense and Military Conflict\": 7\n",
      "}\n",
      "}, output2: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 12,\n",
      "        \"Politics and Governance\": 10,\n",
      "        \"Culture, Religion and Ethnicity\": 8,\n",
      "        \"History\": 14,\n",
      "        \"Geography and Borders\": 18,\n",
      "        \"International Relations and Influence\": 10,\n",
      "        \"Defense and Military Conflict\": 9\n",
      "    }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.S.R.-Poland, Temperature: 0.5, output1: {\n",
      "\"score\": 7\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "\"Economy\": 6,\n",
      "\"Politics and Governance\": 5,\n",
      "\"Culture, Religion and Ethnicity\": 7,\n",
      "\"History\": 10,\n",
      "\"Geography and Borders\": 8,\n",
      "\"International Relations and Influence\": 5,\n",
      "\"Defense and Military Conflict\": 6\n",
      "}\n",
      "}\n",
      "for Model_name: gpt-4, Pair: China-Albania, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "\"Economy\": 5,\n",
      "\"Politics and Governance\": 3,\n",
      "\"Culture, Religion and Ethnicity\": 2,\n",
      "\"History\": 4,\n",
      "\"Geography and Borders\": 2,\n",
      "\"International Relations and Influence\": 6,\n",
      "\"Defense and Military Conflict\": 4\n",
      "}\n",
      "}, output2: {\n",
      "    \"score\": 5\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.A.-Israel, Temperature: 0.5, output1: {\n",
      "    \"Economy\": 12,\n",
      "    \"Politics and Governance\": 14,\n",
      "    \"Culture, Religion and Ethnicity\": 6,\n",
      "    \"History\": 8,\n",
      "    \"Geography and Borders\": 2,\n",
      "    \"International Relations and Influence\": 16,\n",
      "    \"Defense and Military Conflict\": 15\n",
      "}, output2: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 12,\n",
      "        \"Politics and Governance\": 10,\n",
      "        \"Culture, Religion and Ethnicity\": 7,\n",
      "        \"History\": 8,\n",
      "        \"Geography and Borders\": 4,\n",
      "        \"International Relations and Influence\": 13,\n",
      "        \"Defense and Military Conflict\": 16\n",
      "    }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: Japan-Philippines, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "\"Economy\": 8,\n",
      "\"Politics and Governance\": 7,\n",
      "\"Culture, Religion and Ethnicity\": 5,\n",
      "\"History\": 6,\n",
      "\"Geography and Borders\": 10,\n",
      "\"International Relations and Influence\": 9,\n",
      "\"Defense and Military Conflict\": 7\n",
      "}\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "\"Economy\": 8,\n",
      "\"Politics and Governance\": 7,\n",
      "\"Culture, Religion and Ethnicity\": 6,\n",
      "\"History\": 5,\n",
      "\"Geography and Borders\": 10,\n",
      "\"International Relations and Influence\": 8,\n",
      "\"Defense and Military Conflict\": 7\n",
      "}\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.A.-Canada, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "\"Economy\": 15,\n",
      "\"Politics and Governance\": 12,\n",
      "\"Culture, Religion and Ethnicity\": 14,\n",
      "\"History\": 13,\n",
      "\"Geography and Borders\": 18,\n",
      "\"International Relations and Influence\": 16,\n",
      "\"Defense and Military Conflict\": 10\n",
      "}\n",
      "}, output2: {\n",
      "  \"Economy\": 15,\n",
      "  \"Politics and Governance\": 12,\n",
      "  \"Culture, Religion and Ethnicity\": 13,\n",
      "  \"History\": 14,\n",
      "  \"Geography and Borders\": 20,\n",
      "  \"International Relations and Influence\": 16,\n",
      "  \"Defense and Military Conflict\": 12\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.S.R.-Israel, Temperature: 0.5, output1: {\n",
      "    \"score\": 5\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "\"Economy\": 4,\n",
      "\"Politics and Governance\": 3,\n",
      "\"Culture, Religion and Ethnicity\": 2,\n",
      "\"History\": 3,\n",
      "\"Geography and Borders\": 1,\n",
      "\"International Relations and Influence\": 5,\n",
      "\"Defense and Military Conflict\": 6\n",
      "}\n",
      "}\n",
      "for Model_name: gpt-4, Pair: England-Ireland, Temperature: 0.5, output1: {\n",
      "    \"Economy\": 15,\n",
      "    \"Politics and Governance\": 13,\n",
      "    \"Culture, Religion and Ethnicity\": 14,\n",
      "    \"History\": 18,\n",
      "    \"Geography and Borders\": 19,\n",
      "    \"International Relations and Influence\": 12,\n",
      "    \"Defense and Military Conflict\": 10\n",
      "}, output2: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 14,\n",
      "        \"Politics and Governance\": 12,\n",
      "        \"Culture, Religion and Ethnicity\": 15,\n",
      "        \"History\": 13,\n",
      "        \"Geography and Borders\": 20,\n",
      "        \"International Relations and Influence\": 13,\n",
      "        \"Defense and Military Conflict\": 10\n",
      "    }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: Germany-Austria, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "    \"Economy\": 17,\n",
      "    \"Politics and Governance\": 15,\n",
      "    \"Culture, Religion and Ethnicity\": 18,\n",
      "    \"History\": 19,\n",
      "    \"Geography and Borders\": 20,\n",
      "    \"International Relations and Influence\": 16,\n",
      "    \"Defense and Military Conflict\": 14\n",
      "  }\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "\"Economy\": 18,\n",
      "\"Politics and Governance\": 15,\n",
      "\"Culture, Religion and Ethnicity\": 17,\n",
      "\"History\": 16,\n",
      "\"Geography and Borders\": 20,\n",
      "\"International Relations and Influence\": 16,\n",
      "\"Defense and Military Conflict\": 14\n",
      "}\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.S.R.-France, Temperature: 0.5, output1: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 5,\n",
      "        \"Politics and Governance\": 4,\n",
      "        \"Culture, Religion and Ethnicity\": 2,\n",
      "        \"History\": 3,\n",
      "        \"Geography and Borders\": 4,\n",
      "        \"International Relations and Influence\": 6,\n",
      "        \"Defense and Military Conflict\": 5\n",
      "    }\n",
      "}, output2: {\n",
      "    \"Economy\": 5,\n",
      "    \"Politics and Governance\": 4,\n",
      "    \"Culture, Religion and Ethnicity\": 3,\n",
      "    \"History\": 6,\n",
      "    \"Geography and Borders\": 4,\n",
      "    \"International Relations and Influence\": 7,\n",
      "    \"Defense and Military Conflict\": 5\n",
      "}\n",
      "for Model_name: gpt-4, Pair: Belgium-Luxembourg, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "\"Economy\": 15,\n",
      "\"Politics and Governance\": 14,\n",
      "\"Culture, Religion and Ethnicity\": 16,\n",
      "\"History\": 17,\n",
      "\"Geography and Borders\": 20,\n",
      "\"International Relations and Influence\": 13,\n",
      "\"Defense and Military Conflict\": 12\n",
      "}\n",
      "}, output2: {\n",
      "  \"score\": {\n",
      "    \"Economy\": 15,\n",
      "    \"Politics and Governance\": 14,\n",
      "    \"Culture, Religion and Ethnicity\": 16,\n",
      "    \"History\": 16,\n",
      "    \"Geography and Borders\": 20,\n",
      "    \"International Relations and Influence\": 13,\n",
      "    \"Defense and Military Conflict\": 12\n",
      "  }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.A.-U.S.S.R., Temperature: 0.5, output1: {\n",
      "    \"Economy\": 5,\n",
      "    \"Politics and Governance\": 3,\n",
      "    \"Culture, Religion and Ethnicity\": 4,\n",
      "    \"History\": 6,\n",
      "    \"Geography and Borders\": 7,\n",
      "    \"International Relations and Influence\": 8,\n",
      "    \"Defense and Military Conflict\": 6\n",
      "}, output2: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 5,\n",
      "        \"Politics and Governance\": 3,\n",
      "        \"Culture, Religion and Ethnicity\": 4,\n",
      "        \"History\": 6,\n",
      "        \"Geography and Borders\": 7,\n",
      "        \"International Relations and Influence\": 5,\n",
      "        \"Defense and Military Conflict\": 6\n",
      "    }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: China-North Korea, Temperature: 0.5, output1: {\n",
      "    \"Economy\": 5,\n",
      "    \"Politics and Governance\": 15,\n",
      "    \"Culture, Religion and Ethnicity\": 10,\n",
      "    \"History\": 12,\n",
      "    \"Geography and Borders\": 13,\n",
      "    \"International Relations and Influence\": 8,\n",
      "    \"Defense and Military Conflict\": 15\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "\"Economy\": 8,\n",
      "\"Politics and Governance\": 15,\n",
      "\"Culture, Religion and Ethnicity\": 10,\n",
      "\"History\": 13,\n",
      "\"Geography and Borders\": 15,\n",
      "\"International Relations and Influence\": 6,\n",
      "\"Defense and Military Conflict\": 12\n",
      "}\n",
      "}\n",
      "for Model_name: gpt-4, Pair: India-Sri Lanka, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "    \"Economy\": 8,\n",
      "    \"Politics and Governance\": 7,\n",
      "    \"Culture, Religion and Ethnicity\": 13,\n",
      "    \"History\": 12,\n",
      "    \"Geography and Borders\": 10,\n",
      "    \"International Relations and Influence\": 8,\n",
      "    \"Defense and Military Conflict\": 6\n",
      "  }\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "    \"Economy\": 15,\n",
      "    \"Politics and Governance\": 12,\n",
      "    \"Culture, Religion and Ethnicity\": 18,\n",
      "    \"History\": 16,\n",
      "    \"Geography and Borders\": 14,\n",
      "    \"International Relations and Influence\": 13,\n",
      "    \"Defense and Military Conflict\": 10\n",
      "  }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.A.-France, Temperature: 0.5, output1: {\n",
      "    \"Economy\": 12,\n",
      "    \"Politics and Governance\": 8,\n",
      "    \"Culture, Religion and Ethnicity\": 5,\n",
      "    \"History\": 7,\n",
      "    \"Geography and Borders\": 3,\n",
      "    \"International Relations and Influence\": 15,\n",
      "    \"Defense and Military Conflict\": 10\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "\"Economy\": 14,\n",
      "\"Politics and Governance\": 13,\n",
      "\"Culture, Religion and Ethnicity\": 7,\n",
      "\"History\": 10,\n",
      "\"Geography and Borders\": 2,\n",
      "\"International Relations and Influence\": 15,\n",
      "\"Defense and Military Conflict\": 12\n",
      "}\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.S.R.-Cuba, Temperature: 0.5, output1: {\n",
      "\"score\": 10\n",
      "}, output2: {\n",
      "    \"Economy\": 15,\n",
      "    \"Politics and Governance\": 18,\n",
      "    \"Culture, Religion and Ethnicity\": 5,\n",
      "    \"History\": 13,\n",
      "    \"Geography and Borders\": 3,\n",
      "    \"International Relations and Influence\": 16,\n",
      "    \"Defense and Military Conflict\": 14\n",
      "}\n",
      "for Model_name: gpt-4, Pair: England-Jordan, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "    \"Economy\": 5,\n",
      "    \"Politics and Governance\": 5,\n",
      "    \"Culture, Religion and Ethnicity\": 3,\n",
      "    \"History\": 4,\n",
      "    \"Geography and Borders\": 2,\n",
      "    \"International Relations and Influence\": 7,\n",
      "    \"Defense and Military Conflict\": 6\n",
      "  }\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "    \"Economy\": 5,\n",
      "    \"Politics and Governance\": 6,\n",
      "    \"Culture, Religion and Ethnicity\": 2,\n",
      "    \"History\": 4,\n",
      "    \"Geography and Borders\": 1,\n",
      "    \"International Relations and Influence\": 8,\n",
      "    \"Defense and Military Conflict\": 5\n",
      "    }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: France-Israel, Temperature: 0.5, output1: {\n",
      "\"score\": {\n",
      "    \"Economy\": 7,\n",
      "    \"Politics and Governance\": 6,\n",
      "    \"Culture, Religion and Ethnicity\": 3,\n",
      "    \"History\": 4,\n",
      "    \"Geography and Borders\": 2,\n",
      "    \"International Relations and Influence\": 8,\n",
      "    \"Defense and Military Conflict\": 5\n",
      "  }\n",
      "}, output2: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 10,\n",
      "        \"Politics and Governance\": 8,\n",
      "        \"Culture, Religion and Ethnicity\": 5,\n",
      "        \"History\": 7,\n",
      "        \"Geography and Borders\": 3,\n",
      "        \"International Relations and Influence\": 11,\n",
      "        \"Defense and Military Conflict\": 12\n",
      "    }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.A.-Germany, Temperature: 0.5, output1: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 15,\n",
      "        \"Politics and Governance\": 12,\n",
      "        \"Culture, Religion and Ethnicity\": 7,\n",
      "        \"History\": 8,\n",
      "        \"Geography and Borders\": 5,\n",
      "        \"International Relations and Influence\": 18,\n",
      "        \"Defense and Military Conflict\": 16\n",
      "    },\n",
      "    \"overall_similarity\": 11.57\n",
      "}, output2: {\n",
      "\"score\": {\n",
      "    \"Economy\": 15,\n",
      "    \"Politics and Governance\": 12,\n",
      "    \"Culture, Religion and Ethnicity\": 8,\n",
      "    \"History\": 10,\n",
      "    \"Geography and Borders\": 7,\n",
      "    \"International Relations and Influence\": 16,\n",
      "    \"Defense and Military Conflict\": 11\n",
      "    }\n",
      "}\n",
      "for Model_name: gpt-4, Pair: U.S.S.R.-Syria, Temperature: 0.5, output1: {\n",
      "    \"Economy\": 5,\n",
      "    \"Politics and Governance\": 7,\n",
      "    \"Culture, Religion and Ethnicity\": 3,\n",
      "    \"History\": 6,\n",
      "    \"Geography and Borders\": 4,\n",
      "    \"International Relations and Influence\": 7,\n",
      "    \"Defense and Military Conflict\": 8\n",
      "}, output2: {\n",
      "    \"Economy\": 3,\n",
      "    \"Politics and Governance\": 5,\n",
      "    \"Culture, Religion and Ethnicity\": 2,\n",
      "    \"History\": 3,\n",
      "    \"Geography and Borders\": 2,\n",
      "    \"International Relations and Influence\": 4,\n",
      "    \"Defense and Military Conflict\": 6\n",
      "}\n",
      "for Model_name: gpt-4, Pair: France-Algeria, Temperature: 0.5, output1: {\n",
      "\"score\": 7\n",
      "}, output2: {\n",
      "    \"score\": {\n",
      "        \"Economy\": 6,\n",
      "        \"Politics and Governance\": 4,\n",
      "        \"Culture, Religion and Ethnicity\": 7,\n",
      "        \"History\": 10,\n",
      "        \"Geography and Borders\": 3,\n",
      "        \"International Relations and Influence\": 5,\n",
      "        \"Defense and Military Conflict\": 4\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "settings = [('llama3_8B', '0.001', 'SST'), ('llama3_8B', '0.5', 'SST'), ('gpt-4', '0.5', 'SSD') ]\n",
    "for setting in settings:\n",
    "    model_name = setting[0]\n",
    "    temperature = float(setting[1])\n",
    "    model_type = model_name_type_mapping[model_name]\n",
    "    results_dict_columns['model_name'] = model_name\n",
    "    model = initialise_models(model_name, model_type, temperature)\n",
    "    # print(f'model is {model_name}, temperature is {temperature}')\n",
    "    results_dict_columns['temperature'] = temperature\n",
    "    prompt_context = setting[2][0]\n",
    "    prompt_style = ''.join(setting[2][1:])\n",
    "    # print(prompt_context)\n",
    "    # print(prompt_style)\n",
    "    results_dict_columns['prompt_style'] = prompt_context\n",
    "    questions_1 = prompt_style_template_mapping[prompt_style]['order_1']\n",
    "    questions_2 = prompt_style_template_mapping[prompt_style]['order_2']\n",
    "    for order_1, order_2 in zip(questions_1, questions_2):\n",
    "        # print(f'order_1: {order_1}')\n",
    "        results_dict_columns['country_pair'] = order_1\n",
    "        ques_1 = questions_1[order_1]\n",
    "        ques_2 = questions_2[order_2]\n",
    "        # print(f'ques_1: {ques_1}')\n",
    "        output_1 = get_output(prompt, model, order_1, model_name, temperature, ques_1)\n",
    "        output_2 = get_output(prompt, model, order_2, model_name, temperature, ques_2)\n",
    "        parsed_output_1 = parse_numeric_output(output_1)\n",
    "        if  parsed_output_1:\n",
    "                sim_score_1 = int(parsed_output_1)\n",
    "        else:\n",
    "            output_1 = get_output(modified_prompt, model, order_1, model_name, temperature, ques_1)\n",
    "            parsed_output_1 = parse_numeric_output(output_1)\n",
    "            if  parsed_output_1:\n",
    "                sim_score_1 = int(parsed_output_1)\n",
    "            else:\n",
    "                sim_score_1 = None\n",
    "                print(f' cannot parse output {output_1} for Model_name: {model_name}, Pair: {order_1}, Temperature: {temperature}')\n",
    "        parsed_output_2 = parse_numeric_output(output_2)\n",
    "        if parsed_output_2:\n",
    "            sim_score_2 = int(parsed_output_2)\n",
    "            \n",
    "        else:\n",
    "            output_2 = get_output(modified_prompt, model, order_2, model_name, temperature, ques_2)\n",
    "            parsed_output_2 = parse_numeric_output(output_2)\n",
    "            if  parsed_output_2:\n",
    "                sim_score_2 = int(parsed_output_2)\n",
    "            else:\n",
    "                sim_score_2 = None\n",
    "                print(f' cannot parse output {output_2} for Model_name: {model_name}, Pair: {order_2}, Temperature: {temperature}')\n",
    "        if sim_score_1!=None and sim_score_2!=None:\n",
    "            sim_diff = sim_score_1 - sim_score_2\n",
    "        else:\n",
    "            sim_diff = None\n",
    "        print(f'for Model_name: {model_name}, Pair: {order_1}, Temperature: {temperature}, output1: {output_1}, output2: {output_2}')\n",
    "        results_dict_columns['sim_score_1'] = sim_score_1\n",
    "        results_dict_columns['sim_score_2'] = sim_score_2\n",
    "        results_dict_columns['sim_diff'] = sim_diff\n",
    "        df = pd.concat([df, pd.DataFrame.from_dict([results_dict_columns])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_pair</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>model_name</th>\n",
       "      <th>temperature</th>\n",
       "      <th>sim_score_1</th>\n",
       "      <th>sim_score_2</th>\n",
       "      <th>sim_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.A.-Mexico</td>\n",
       "      <td>S</td>\n",
       "      <td>llama3_8B</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.S.R.-Poland</td>\n",
       "      <td>S</td>\n",
       "      <td>llama3_8B</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China-Albania</td>\n",
       "      <td>S</td>\n",
       "      <td>llama3_8B</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.A.-Israel</td>\n",
       "      <td>S</td>\n",
       "      <td>llama3_8B</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan-Philippines</td>\n",
       "      <td>S</td>\n",
       "      <td>llama3_8B</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.S.R.-Cuba</td>\n",
       "      <td>S</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.500</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England-Jordan</td>\n",
       "      <td>S</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France-Israel</td>\n",
       "      <td>S</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.A.-Germany</td>\n",
       "      <td>S</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.500</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.S.R.-Syria</td>\n",
       "      <td>S</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         country_pair prompt_style model_name  temperature sim_score_1  \\\n",
       "0       U.S.A.-Mexico            S  llama3_8B        0.001          12   \n",
       "0     U.S.S.R.-Poland            S  llama3_8B        0.001           8   \n",
       "0       China-Albania            S  llama3_8B        0.001           2   \n",
       "0       U.S.A.-Israel            S  llama3_8B        0.001           8   \n",
       "0   Japan-Philippines            S  llama3_8B        0.001           8   \n",
       "..                ...          ...        ...          ...         ...   \n",
       "0       U.S.S.R.-Cuba            S      gpt-4        0.500          10   \n",
       "0      England-Jordan            S      gpt-4        0.500           5   \n",
       "0       France-Israel            S      gpt-4        0.500           7   \n",
       "0      U.S.A.-Germany            S      gpt-4        0.500          15   \n",
       "0      U.S.S.R.-Syria            S      gpt-4        0.500           5   \n",
       "\n",
       "   sim_score_2 sim_diff  \n",
       "0           12        0  \n",
       "0            2        6  \n",
       "0            2        0  \n",
       "0           12       -4  \n",
       "0            8        0  \n",
       "..         ...      ...  \n",
       "0           15       -5  \n",
       "0            5        0  \n",
       "0           10       -3  \n",
       "0           15        0  \n",
       "0            3        2  \n",
       "\n",
       "[62 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ \n",
    "    'mistral_7B',\n",
    " 'llama2_7B',\n",
    "  'llama3_8B',\n",
    " 'llama2_13B',\n",
    "  'gpt-3.5-turbo',\n",
    " 'gpt-4'\n",
    "]\n",
    "models = ['llama3_70B']\n",
    "for model_name in models:\n",
    "    model_type = model_name_type_mapping[model_name]\n",
    "    results_dict_columns['model_name'] = model_name\n",
    "    for temperature in temperatures[:1]:\n",
    "        model = initialise_models(model_name, model_type, temperature)\n",
    "        results_dict_columns['temperature'] = temperature\n",
    "        for order_1, order_2 in zip(questions_order_similar_to_1, questions_order_similar_to_2):\n",
    "            results_dict_columns['country_pair'] = order_1\n",
    "            ques_1 = questions_order_similar_degree_1[order_1]\n",
    "            ques_2 = questions_order_similar_degree_2[order_2]\n",
    "            output_1 = get_output(prompt, model, order_1, model_name, temperature, ques_1)\n",
    "            output_2 = get_output(prompt, model, order_2, model_name, temperature, ques_2)\n",
    "            # print(output_1)\n",
    "            reasoning_1, sim_score_1, error_1 = parse_cot_json_output(output_1)\n",
    "            reasoning_2, sim_score_2, error_2 = parse_cot_json_output(output_2)\n",
    "            # if error_1 or error_2:\n",
    "            #     df.to_csv(file_path, index=False, mode='w')\n",
    "            if sim_score_1!=None and sim_score_2!=None:\n",
    "                sim_diff = sim_score_1 - sim_score_2\n",
    "            else:\n",
    "                sim_diff = None\n",
    "            print(f'for Model_name: {model_name}, Pair: {order_2}, Temperature: {temperature}, output1: {output_1}, output2: {output_2}')\n",
    "            results_dict_columns['sim_score_1'] = sim_score_1\n",
    "            results_dict_columns['sim_score_2'] = sim_score_2\n",
    "            results_dict_columns['sim_diff'] = sim_diff\n",
    "            results_dict_columns['cot_reasoning_1'] = reasoning_1\n",
    "            results_dict_columns['cot_reasoning_2'] = reasoning_2\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame.from_dict([results_dict_columns])])\n",
    "            # del model\n",
    "        # print('model deleted..')\n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_path, index=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model deleted..\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "print('model deleted..')\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
